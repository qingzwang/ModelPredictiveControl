import pandas as pd
import numpy as np
import json
import tqdm
from typing import Tuple, Optional, Union
from concurrent.futures import ThreadPoolExecutor
import concurrent.futures
import matplotlib.pyplot as plt
from matplotlib import font_manager
import seaborn as sns
import os

#plt.rcParams['font.sans-serif'] = ['Heiti TC', 'DejaVu Sans', "SourceHanSansSC-Normal.otf"]
#zhfont1 = FontProperties(fname="SourceHanSansSC-Normal.otf", size = 15)
font_path = 'SourceHanSansSC-Normal.otf'  # Your font path goes here
font_manager.fontManager.addfont(font_path)
prop = font_manager.FontProperties(fname=font_path)

plt.rcParams['font.family'] = 'sans-serif'
plt.rcParams['font.sans-serif'] = prop.get_name()

TIME_MATCHING = {
    0: "00:00:00",
    1: "01:00:00",
    2: "02:00:00",
    3: "03:00:00",
    4: "04:00:00",
    5: "05:00:00",
    6: "06:00:00",
    7: "07:00:00",
    8: "08:00:00",
    9: "09:00:00",
    10: "10:00:00",
    11: "11:00:00",
    12: "12:00:00",
    13: "13:00:00",
    14: "14:00:00",
    15: "15:00:00",
    16: "16:00:00",
    17: "17:00:00",
    18: "18:00:00",
    19: "19:00:00",
    20: "20:00:00",
    21: "21:00:00",
    22: "22:00:00",
    23: "23:00:00"
}


def get_time_string(hour: int) -> str:
    """
    TIME_MATCHINGåŠŸèƒ½ï¼šå°†å°æ—¶æ•°å­—è½¬æ¢ä¸ºæ—¶é—´å­—ç¬¦ä¸²
    
    Args:
        hour: å°æ—¶æ•° (0-23)
    
    Returns:
        str: æ—¶é—´å­—ç¬¦ä¸²æ ¼å¼ "HH:00:00"
    """
    if hour in TIME_MATCHING:
        return TIME_MATCHING[hour]
    else:
        # å¯¹äºè¶…å‡ºèŒƒå›´çš„å€¼ï¼Œè¿”å›Noneæˆ–æŠ›å‡ºå¼‚å¸¸
        raise ValueError(f"Invalid hour: {hour}. Hour must be between 0 and 23.")


def extract_load_sun_data(load_data: Union[str, pd.DataFrame], sun_data: Union[str, pd.DataFrame], tariff_data: Union[str, pd.DataFrame],
                         gateway_id: str, datetime: str) -> Optional[Tuple[float, float, float, float, float, float]]:
    """
    ä»loadã€sunå’Œtariffæ•°æ®ä¸­æå–æŒ‡å®šgateway_idå’Œdatetimeçš„æ•°æ®
    
    Args:
        load_data: load CSVæ–‡ä»¶è·¯å¾„(str)æˆ–å·²è¯»å–çš„DataFrame
        sun_data: sun CSVæ–‡ä»¶è·¯å¾„(str)æˆ–å·²è¯»å–çš„DataFrame  
        tariff_data: tariff CSVæ–‡ä»¶è·¯å¾„(str)æˆ–å·²è¯»å–çš„DataFrame
        gateway_id: ç½‘å…³ID
        datetime: æ—¶é—´å­—ç¬¦ä¸² (æ ¼å¼: 'YYYY-MM-DD HH:MM:SS')
    
    Returns:
        tuple: (load_pred, load, sun_pred, sun, buy_price, sell_price) å¦‚æœæ‰¾åˆ°æ•°æ®ï¼Œå¦åˆ™è¿”å›None
    """
    try:
        # æ”¯æŒä¼ å…¥DataFrameæˆ–æ–‡ä»¶è·¯å¾„
        load_df = pd.read_csv(load_data) if isinstance(load_data, str) else load_data
        sun_df = pd.read_csv(sun_data) if isinstance(sun_data, str) else sun_data
        tariff_df = pd.read_csv(tariff_data) if isinstance(tariff_data, str) else tariff_data
        
        # æŸ¥æ‰¾æŒ‡å®šgateway_idå’Œdatetimeçš„è®°å½•
        load_record = load_df[(load_df['gateway_id'] == gateway_id) & 
                             (load_df['datetime'] == datetime)]
        sun_record = sun_df[(sun_df['gateway_id'] == gateway_id) & 
                           (sun_df['datetime'] == datetime)]
        tariff_record = tariff_df[(tariff_df['gateway_id'] == gateway_id) & 
                                 (tariff_df['device_time'] == datetime)]
        
        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°åŒ¹é…è®°å½•
        if load_record.empty or sun_record.empty or tariff_record.empty:
            return None
        
        # æå–æ•°æ®
        load_pred = float(load_record.iloc[0]['kwh_load_predict'])
        load = float(load_record.iloc[0]['kwh_load'])
        sun_pred = float(sun_record.iloc[0]['kwh_sun_predict'])
        sun = float(sun_record.iloc[0]['kwh_sun'])
        buy_price = float(tariff_record.iloc[0]['tariff_price'])
        sell_price = float(tariff_record.iloc[0]['tariff_sell_price'])
        
        return (load_pred, load, sun_pred, sun, buy_price, sell_price)
        
    except Exception as e:
        print(f"Error extracting data: {e}")
        return None


def extract_all_matching_data(load_data: Union[str, pd.DataFrame], sun_data: Union[str, pd.DataFrame], tariff_data: Union[str, pd.DataFrame],
                             gateway_id: str) -> pd.DataFrame:
    """
    æå–æŒ‡å®šgateway_idçš„æ‰€æœ‰åŒ¹é…æ—¶é—´ç‚¹çš„æ•°æ®
    
    Args:
        load_data: load CSVæ–‡ä»¶è·¯å¾„(str)æˆ–å·²è¯»å–çš„DataFrame
        sun_data: sun CSVæ–‡ä»¶è·¯å¾„(str)æˆ–å·²è¯»å–çš„DataFrame  
        tariff_data: tariff CSVæ–‡ä»¶è·¯å¾„(str)æˆ–å·²è¯»å–çš„DataFrame
        gateway_id: ç½‘å…³ID
    
    Returns:
        DataFrame: åŒ…å«åŒ¹é…æ•°æ®çš„DataFrameï¼Œåˆ—ä¸º [datetime, load_pred, load, sun_pred, sun, buy_price, sell_price]
    """
    try:
        # æ”¯æŒä¼ å…¥DataFrameæˆ–æ–‡ä»¶è·¯å¾„
        load_df = pd.read_csv(load_data) if isinstance(load_data, str) else load_data
        sun_df = pd.read_csv(sun_data) if isinstance(sun_data, str) else sun_data
        tariff_df = pd.read_csv(tariff_data) if isinstance(tariff_data, str) else tariff_data
        
        # ç­›é€‰æŒ‡å®šgateway_idçš„æ•°æ®
        load_filtered = load_df[load_df['gateway_id'] == gateway_id]
        sun_filtered = sun_df[sun_df['gateway_id'] == gateway_id]
        tariff_filtered = tariff_df[tariff_df['gateway_id'] == gateway_id]
        
        # å…ˆåˆå¹¶loadå’Œsunæ•°æ®
        merged_df = pd.merge(load_filtered, sun_filtered, on=['gateway_id', 'datetime'])
        
        # å†åˆå¹¶tariffæ•°æ®ï¼Œä½¿ç”¨device_timeåŒ¹é…datetime
        merged_df = pd.merge(merged_df, tariff_filtered, 
                           left_on=['gateway_id', 'datetime'], 
                           right_on=['gateway_id', 'device_time'])
        
        # é€‰æ‹©éœ€è¦çš„åˆ—å¹¶é‡å‘½å
        result_df = merged_df[['datetime', 'kwh_load_predict', 'kwh_load', 
                              'kwh_sun_predict', 'kwh_sun', 'tariff_price', 'tariff_sell_price']].copy()
        result_df.columns = ['datetime', 'load_pred', 'load', 'sun_pred', 'sun', 'buy_price', 'sell_price']
        
        return result_df
        
    except Exception as e:
        print(f"Error extracting all matching data: {e}")
        return pd.DataFrame()


def group_by_24h_periods(df: pd.DataFrame) -> list:
    """
    å°†æ•°æ®æŒ‰24å°æ—¶å‘¨æœŸåˆ†ç»„ï¼Œæ¯ç»„å¿…é¡»åŒ…å«å®Œæ•´çš„00:00:00åˆ°23:00:00çš„24ä¸ªç‚¹
    ä¸æ»¡è¶³24å°æ—¶çš„æ•°æ®ä¼šè¢«ä¸¢å¼ƒ
    
    Args:
        df: åŒ…å«datetimeåˆ—çš„DataFrame
    
    Returns:
        list: æ¯ä¸ªå…ƒç´ æ˜¯ä¸€ä¸ªåŒ…å«24å°æ—¶å®Œæ•´æ•°æ®çš„DataFrame
    """
    try:
        # ç¡®ä¿datetimeåˆ—æ˜¯datetimeç±»å‹
        df['datetime'] = pd.to_datetime(df['datetime'])
        
        # æŒ‰æ—¥æœŸåˆ†ç»„
        df['date'] = df['datetime'].dt.date
        grouped = df.groupby('date')
        
        valid_groups = []
        
        for date, group in grouped:
            # æ£€æŸ¥æ˜¯å¦æœ‰24ä¸ªå°æ—¶çš„æ•°æ®
            hours = group['datetime'].dt.hour.unique()
            
            # æ£€æŸ¥æ˜¯å¦åŒ…å«0-23æ‰€æœ‰å°æ—¶
            expected_hours = set(range(24))
            actual_hours = set(hours)
            
            if actual_hours == expected_hours:
                # æŒ‰å°æ—¶æ’åº
                group_sorted = group.sort_values('datetime').reset_index(drop=True)
                valid_groups.append(group_sorted)
        
        return valid_groups
        
    except Exception as e:
        print(f"Error grouping data by 24h periods: {e}")
        return []


def extract_rule_data(rule_data: Union[str, pd.DataFrame], gateway_id: str, datetime: str) -> Optional[Tuple[str, list, list, int, int]]:
    """
    ä»è§„åˆ™é…ç½®æ•°æ®ä¸­æå–æŒ‡å®šgateway_idå’Œdatetimeçš„é…ç½®ä¿¡æ¯
    
    Args:
        rule_data: è§„åˆ™é…ç½®CSVæ–‡ä»¶è·¯å¾„(str)æˆ–å·²è¯»å–çš„DataFrame
        gateway_id: ç½‘å…³ID
        datetime: æ—¶é—´å­—ç¬¦ä¸² (æ ¼å¼: 'YYYY-MM-DD HH:MM:SS')
    
    Returns:
        tuple: (dispatch_code, load_priority_list, solar_priority_list, grid_charge_max, grid_discharge_max) 
               å…¶ä¸­priority_listæ˜¯3å…ƒç´ åˆ—è¡¨ï¼Œå¦‚120.0->[1,2,0], 123.0->[1,2,3], 12.0->[0,1,2]
               å¦‚æœæ‰¾åˆ°æ•°æ®ï¼Œå¦åˆ™è¿”å›None
    """
    try:
        import pandas as pd
        from datetime import datetime as dt
        
        def priority_to_list(priority_val):
            """å°†priorityæ•°å­—è½¬æ¢ä¸º3å…ƒç´ åˆ—è¡¨"""
            # å°†æ•°å­—è½¬ä¸ºå­—ç¬¦ä¸²ï¼Œå–å‰3ä½æ•°å­—
            priority_str = str(int(priority_val))
            if len(priority_str) >= 3:
                return [int(priority_str[0]), int(priority_str[1]), int(priority_str[2])]
            elif len(priority_str) == 2:
                return [0, int(priority_str[0]), int(priority_str[1])]
            elif len(priority_str) == 1:
                return [0, 0, int(priority_str[0])]
            else:
                return [0, 0, 0]
        
        # æ”¯æŒä¼ å…¥DataFrameæˆ–æ–‡ä»¶è·¯å¾„
        rule_df = pd.read_csv(rule_data) if isinstance(rule_data, str) else rule_data
        
        # è§£æè¾“å…¥çš„datetime
        input_dt = dt.strptime(datetime, '%Y-%m-%d %H:%M:%S')
        input_date = input_dt.strftime('%Y-%m-%d')
        input_time = input_dt.strftime('%H:%M')
        
        # ç­›é€‰æŒ‡å®šgateway_idå’Œæ—¥æœŸçš„è®°å½•
        filtered_df = rule_df[(rule_df['gateway_id'] == gateway_id) & 
                             (rule_df['device_time'] == input_date)]
        
        if filtered_df.empty:
            return None
        
        # æŸ¥æ‰¾æ—¶é—´èŒƒå›´åŒ¹é…çš„è§„åˆ™
        for _, row in filtered_df.iterrows():
            start_time = row['start_time']
            end_time = row['end_time']
            
            # å¤„ç†æ—¶é—´æ ¼å¼
            if len(start_time.split(':')) == 2:
                start_time = start_time + ':00'
            
            # å¤„ç†ç‰¹æ®Šæ—¶é—´æ ¼å¼ (24:00è¡¨ç¤ºå½“å¤©ç»“æŸ)
            if end_time == '24:00':
                end_time = '23:59:59'
            elif len(end_time.split(':')) == 2:
                end_time = end_time + ':00'
            
            # è½¬æ¢ä¸ºæ—¶é—´å¯¹è±¡è¿›è¡Œæ¯”è¾ƒ
            start_dt = dt.strptime(start_time, '%H:%M:%S').time()
            end_dt = dt.strptime(end_time, '%H:%M:%S').time()
            input_time_obj = input_dt.time()
            
            # æ£€æŸ¥æ—¶é—´æ˜¯å¦åœ¨èŒƒå›´å†…
            if start_dt <= input_time_obj <= end_dt:
                dispatch_code = str(row['dispatch_code'])
                load_priority_list = priority_to_list(row['load_priority'])
                solar_priority_list = priority_to_list(row['solar_priority'])
                
                # å¤„ç†grid_charge_maxå’Œgrid_discharge_maxçš„NaNå€¼
                try:
                    grid_charge_max = int(float(row['grid_charge_max'])) if not pd.isna(row['grid_charge_max']) else 0
                except (ValueError, TypeError):
                    grid_charge_max = 0
                    
                try:
                    grid_discharge_max = int(float(row['grid_discharge_max'])) if not pd.isna(row['grid_discharge_max']) else 0
                except (ValueError, TypeError):
                    grid_discharge_max = 0
                
                return (dispatch_code, load_priority_list, solar_priority_list, grid_charge_max, grid_discharge_max)
        
        return None
        
    except Exception as e:
        print(f"Error extracting rule data: {e}")
        return None


def extract_rule_data_optimized(rule_filtered_df: pd.DataFrame, datetime: str) -> Optional[Tuple[str, list, list, int, int]]:
    """
    ä¼˜åŒ–ç‰ˆæœ¬ï¼šä»é¢„å…ˆç­›é€‰çš„è§„åˆ™é…ç½®æ•°æ®ä¸­æå–æŒ‡å®šdatetimeçš„é…ç½®ä¿¡æ¯
    
    Args:
        rule_filtered_df: å·²ç­›é€‰çš„è§„åˆ™é…ç½®DataFrameï¼ˆä»…åŒ…å«ç‰¹å®šgateway_idå’Œæ—¥æœŸï¼‰
        datetime: æ—¶é—´å­—ç¬¦ä¸² (æ ¼å¼: 'YYYY-MM-DD HH:MM:SS')
    
    Returns:
        tuple: (dispatch_code, load_priority_list, solar_priority_list, grid_charge_max, grid_discharge_max)
    """
    try:
        from datetime import datetime as dt
        
        def priority_to_list(priority_val):
            """å°†priorityæ•°å­—è½¬æ¢ä¸º3å…ƒç´ åˆ—è¡¨"""
            # å¤„ç†NaNå€¼
            if pd.isna(priority_val):
                return [0, 0, 0]
            
            try:
                priority_int = int(float(priority_val))  # å…ˆè½¬æ¢ä¸ºfloatå†è½¬intï¼Œå¤„ç†å¯èƒ½çš„æµ®ç‚¹æ•°
                priority_str = str(priority_int)
                if len(priority_str) >= 3:
                    return [int(priority_str[0]), int(priority_str[1]), int(priority_str[2])]
                elif len(priority_str) == 2:
                    return [0, int(priority_str[0]), int(priority_str[1])]
                elif len(priority_str) == 1:
                    return [0, 0, int(priority_str[0])]
                else:
                    return [0, 0, 0]
            except (ValueError, TypeError):
                return [0, 0, 0]
        
        # è§£æè¾“å…¥çš„datetime
        input_dt = dt.strptime(datetime, '%Y-%m-%d %H:%M:%S')
        input_time = input_dt.strftime('%H:%M')
        
        if rule_filtered_df.empty:
            return None
        
        # æŸ¥æ‰¾æ—¶é—´èŒƒå›´åŒ¹é…çš„è§„åˆ™
        for _, row in rule_filtered_df.iterrows():
            start_time = row['start_time']
            end_time = row['end_time']
            
            # å¤„ç†æ—¶é—´æ ¼å¼
            if len(start_time.split(':')) == 2:
                start_time = start_time + ':00'
            
            # å¤„ç†ç‰¹æ®Šæ—¶é—´æ ¼å¼ (24:00è¡¨ç¤ºå½“å¤©ç»“æŸ)
            if end_time == '24:00':
                end_time = '23:59:59'
            elif len(end_time.split(':')) == 2:
                end_time = end_time + ':00'
            
            # è½¬æ¢ä¸ºæ—¶é—´å¯¹è±¡è¿›è¡Œæ¯”è¾ƒ
            start_dt = dt.strptime(start_time, '%H:%M:%S').time()
            end_dt = dt.strptime(end_time, '%H:%M:%S').time()
            input_time_obj = input_dt.time()
            
            # æ£€æŸ¥æ—¶é—´æ˜¯å¦åœ¨èŒƒå›´å†…
            if start_dt <= input_time_obj <= end_dt:
                dispatch_code = str(row['dispatch_code'])
                load_priority_list = priority_to_list(row['load_priority'])
                solar_priority_list = priority_to_list(row['solar_priority'])
                
                # å¤„ç†grid_charge_maxå’Œgrid_discharge_maxçš„NaNå€¼
                try:
                    grid_charge_max = int(float(row['grid_charge_max'])) if not pd.isna(row['grid_charge_max']) else 0
                except (ValueError, TypeError):
                    grid_charge_max = 0
                    
                try:
                    grid_discharge_max = int(float(row['grid_discharge_max'])) if not pd.isna(row['grid_discharge_max']) else 0
                except (ValueError, TypeError):
                    grid_discharge_max = 0
                
                return (dispatch_code, load_priority_list, solar_priority_list, grid_charge_max, grid_discharge_max)
        
        return None
        
    except Exception as e:
        print(f"Error extracting optimized rule data: {e}")
        return None


def extract_load_sun_data_optimized(load_lookup: dict, sun_lookup: dict, tariff_lookup: dict,
                                   datetime: str) -> Optional[Tuple[float, float, float, float, float, float]]:
    """
    ä¼˜åŒ–ç‰ˆæœ¬ï¼šä»é¢„å…ˆæ„å»ºçš„æŸ¥æ‰¾å­—å…¸ä¸­æå–æŒ‡å®šdatetimeçš„æ•°æ®
    
    Args:
        load_lookup: è´Ÿè½½æ•°æ®æŸ¥æ‰¾å­—å…¸ {datetime: row_data}
        sun_lookup: å…‰ä¼æ•°æ®æŸ¥æ‰¾å­—å…¸ {datetime: row_data}
        tariff_lookup: ç”µä»·æ•°æ®æŸ¥æ‰¾å­—å…¸ {device_time: row_data}
        datetime: æ—¶é—´å­—ç¬¦ä¸² (æ ¼å¼: 'YYYY-MM-DD HH:MM:SS')
    
    Returns:
        tuple: (load_pred, load, sun_pred, sun, buy_price, sell_price)
    """
    try:
        # ç›´æ¥ä»å­—å…¸ä¸­æŸ¥æ‰¾æ•°æ®ï¼Œæ—¶é—´å¤æ‚åº¦O(1)
        load_record = load_lookup.get(datetime)
        sun_record = sun_lookup.get(datetime)
        tariff_record = tariff_lookup.get(datetime)
        
        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°åŒ¹é…è®°å½•
        if load_record is None or sun_record is None or tariff_record is None:
            return None
        
        # æå–æ•°æ®
        load_pred = float(load_record['kwh_load_predict'])
        load = float(load_record['kwh_load'])
        sun_pred = float(sun_record['kwh_sun_predict'])
        sun = float(sun_record['kwh_sun'])
        buy_price = float(tariff_record['tariff_price'])
        sell_price = float(tariff_record['tariff_sell_price'])
        
        return (load_pred, load, sun_pred, sun, buy_price, sell_price)
        
    except Exception as e:
        print(f"Error extracting optimized load/sun data: {e}")
        return None


def extract_battery_info(battery_data: Union[str, pd.DataFrame], gateway_id: str) -> Optional[dict]:
    """
    ä»ç”µæ± ä¿¡æ¯æ•°æ®ä¸­æå–æŒ‡å®šgateway_idçš„ç”µæ± é…ç½®ä¿¡æ¯
    
    Args:
        battery_data: ç”µæ± ä¿¡æ¯CSVæ–‡ä»¶è·¯å¾„(str)æˆ–å·²è¯»å–çš„DataFrame
        gateway_id: ç½‘å…³ID
    
    Returns:
        dict: åŒ…å«ç”µæ± ä¿¡æ¯çš„å­—å…¸ï¼Œé”®ä¸º [rated_cap, tou_min_soc, battery_soc, battery_count, rated_power]
              å¦‚æœæ‰¾åˆ°æ•°æ®ï¼Œå¦åˆ™è¿”å›None
    """
    try:
        # æ”¯æŒä¼ å…¥DataFrameæˆ–æ–‡ä»¶è·¯å¾„
        battery_df = pd.read_csv(battery_data) if isinstance(battery_data, str) else battery_data
        
        # æŸ¥æ‰¾æŒ‡å®šgateway_idçš„è®°å½•
        battery_record = battery_df[battery_df['gateway_id'] == gateway_id]
        
        # æ£€æŸ¥æ˜¯å¦æ‰¾åˆ°åŒ¹é…è®°å½•
        if battery_record.empty:
            return None
        
        # æå–ç”µæ± ä¿¡æ¯ï¼ˆå–ç¬¬ä¸€æ¡åŒ¹é…è®°å½•ï¼‰
        record = battery_record.iloc[0]
        battery_info = {
            'gateway_id': gateway_id,
            'rated_cap': float(record['rated_cap']),           # é¢å®šå®¹é‡ (kWh)
            'tou_min_soc': float(record['tou_min_soc']),       # TOUæœ€å°SOC (%)
            'battery_soc': float(record['battery_soc']),       # å½“å‰ç”µæ± SOC (%)
            'battery_count': int(record['battery_count']),     # ç”µæ± æ•°é‡
            'rated_power': float(record['rated_power'])        # é¢å®šåŠŸç‡ (kW)
        }
        
        return (battery_info["rated_cap"], battery_info["tou_min_soc"], battery_info["battery_soc"], battery_info["rated_power"])
        
    except Exception as e:
        print(f"Error extracting battery info: {e}")
        return None


def compare_algorithm_performance(vis_dir: str = 'vis') -> dict:
    """
    å¯¹æ¯”åˆ†ævisç›®å½•ä¸­ä¸åŒç®—æ³•çš„æ€§èƒ½è¡¨ç°
    
    é€šè¿‡åˆ†ææ‰€æœ‰å­æ–‡ä»¶å¤¹ä¸­çš„res.jsonæ–‡ä»¶ï¼Œå¯¹æ¯”çº¿æ€§è§„åˆ’ã€åŠ¨æ€è§„åˆ’å’Œè§„åˆ™æ–¹æ³•çš„total_cost
    
    Args:
        vis_dir: visç›®å½•è·¯å¾„ï¼Œé»˜è®¤ä¸º'vis'
        
    Returns:
        dict: åŒ…å«ç®—æ³•æ€§èƒ½å¯¹æ¯”ç»“æœçš„å­—å…¸ï¼Œæ ¼å¼ä¸ºï¼š
        {
            'summary': {
                'linear_programming': {'avg_cost': float, 'count': int, 'costs': list},
                'rule_based': {'avg_cost': float, 'count': int, 'costs': list},
                'dynamic_programming': {'avg_cost': float, 'count': int, 'costs': list}
            },
            'detailed_results': [
                {
                    'gateway_id': str,
                    'date': str, 
                    'linear_programming': float,
                    'rule_based': float,
                    'dynamic_programming': float
                },
                ...
            ],
            'best_algorithm': str,
            'performance_difference': dict
        }
    """
    import os
    import json
    import re
    from collections import defaultdict
    
    try:
        # å­˜å‚¨æ‰€æœ‰ç®—æ³•çš„æˆæœ¬æ•°æ®
        algorithm_costs = {
            'linear_programming': [],
            'rule_based': [],  
            'dynamic_programming': [],
            'hier_mpc':[],
            'rule_pred':[],
            'mpc_rule_gt': [],
            'mpc_rule_pred20': [],
            'mpc_rule_pred50': [],
            'mpc_rule_pred100': []
        }
        
        # å­˜å‚¨è¯¦ç»†å¯¹æ¯”ç»“æœ
        detailed_results = []
        gateway_date_results = defaultdict(dict)
        
        # ç»Ÿè®¡å¤„ç†æƒ…å†µçš„è®¡æ•°å™¨
        success_count = 0
        error_count = 0
        invalid_data_count = 0
        
        # éå†visç›®å½•ä¸‹çš„æ‰€æœ‰å­æ–‡ä»¶å¤¹
        if not os.path.exists(vis_dir):
            print(f"é”™è¯¯: ç›®å½• {vis_dir} ä¸å­˜åœ¨")
            return {}
            
        for folder_name in tqdm.tqdm(os.listdir(vis_dir)):
            folder_path = os.path.join(vis_dir, folder_name)
            
            # è·³è¿‡éç›®å½•æ–‡ä»¶
            if not os.path.isdir(folder_path):
                continue
            
            # æ£€æŸ¥res.jsonæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            res_json_path = os.path.join(folder_path, 'res.json')
            if not os.path.exists(res_json_path):
                continue
            
            # è§£ææ–‡ä»¶å¤¹åç§°ï¼Œç¡®å®šç®—æ³•ç±»å‹
            # æ ¼å¼: gateway_id:...-date:YYYY-MM-DD[-algorithm]
            folder_pattern = r'gateway_id:([^-]+)-date:(\d{4}-\d{2}-\d{2})(?:-(.+))?'
            match = re.match(folder_pattern, folder_name)
            
            if not match:
                continue
                
            gateway_id = match.group(1)
            date = match.group(2)
            algorithm_suffix = match.group(3)
            
            # ç¡®å®šç®—æ³•ç±»å‹
            if algorithm_suffix == 'rule':
                algorithm = 'rule_based'
            elif algorithm_suffix == 'dp':
                algorithm = 'dynamic_programming'
            elif algorithm_suffix == 'lp':
                algorithm = 'linear_programming'
            elif algorithm_suffix == 'lp-grid-constrain':
                algorithm = 'lp_grid_constrain'
            elif algorithm_suffix == 'rule-pred':
                algorithm = 'rule_pred'
            elif algorithm_suffix == 'hier-mpc-grid-constrain-pv0-load0-rule-pred':
                algorithm = 'mpc_rule_gt'
            elif algorithm_suffix == 'hier-mpc-grid-constrain-pv20-load20-rule-pred':
                algorithm = 'mpc_rule_pred20'
            elif algorithm_suffix == 'hier-mpc-grid-constrain-pv50-load50-rule-pred':
                algorithm = 'mpc_rule_pred50'
            elif algorithm_suffix == 'hier-mpc-grid-constrain-pv100-load100-rule-pred':
                algorithm = 'mpc_rule_pred100'
            else:
                continue  # è·³è¿‡æœªçŸ¥çš„ç®—æ³•åç¼€
            
            # è¯»å–res.jsonæ–‡ä»¶
            try:
                with open(res_json_path, 'r', encoding='utf-8') as f:
                    result_data = json.load(f)
                
                # æå–total_cost
                if 'total_cost' in result_data and result_data['status'] == 'optimal':
                    total_cost = result_data['total_cost']
                    
                    # æ£€æŸ¥total_costæ˜¯å¦ä¸ºæœ‰æ•ˆæ•°å€¼
                    if total_cost is not None and not (isinstance(total_cost, float) and np.isnan(total_cost)):
                        try:
                            total_cost = float(total_cost)
                            if not np.isnan(total_cost) and not np.isinf(total_cost):
                                # å­˜å‚¨åˆ°ç®—æ³•æˆæœ¬åˆ—è¡¨
                                algorithm_costs[algorithm].append(total_cost)
                                
                                # å­˜å‚¨åˆ°è¯¦ç»†ç»“æœä¸­ï¼ˆæŒ‰gateway_idå’Œdateåˆ†ç»„ï¼‰
                                key = f"{gateway_id}_{date}"
                                gateway_date_results[key]['gateway_id'] = gateway_id
                                gateway_date_results[key]['date'] = date
                                gateway_date_results[key][algorithm] = total_cost
                                success_count += 1
                        except (ValueError, TypeError):
                            invalid_data_count += 1
                            continue
                    else:
                        invalid_data_count += 1
            except Exception as e:
                error_count += 1
                continue
        
        # æ‰“å°å¤„ç†æ‘˜è¦
        total_processed = success_count + error_count + invalid_data_count
        print(f"\nğŸ“Š æ•°æ®å¤„ç†æ‘˜è¦:")
        print(f"  æˆåŠŸå¤„ç†: {success_count} ä¸ªæ–‡ä»¶")
        if error_count > 0:
            print(f"  JSONè§£æé”™è¯¯: {error_count} ä¸ªæ–‡ä»¶")
        if invalid_data_count > 0:
            print(f"  æ— æ•ˆæ•°æ®: {invalid_data_count} ä¸ªæ–‡ä»¶")
        print(f"  æ€»è®¡: {total_processed} ä¸ªæ–‡ä»¶")
        
        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯
        summary = {}
        for alg, costs in algorithm_costs.items():
            if costs:
                summary[alg] = {
                    'avg_cost': sum(costs) / len(costs),
                    'count': len(costs),
                    'costs': sorted(costs),
                    'min_cost': min(costs),
                    'max_cost': max(costs),
                    'median_cost': sorted(costs)[len(costs)//2] if costs else 0
                }
            else:
                summary[alg] = {
                    'avg_cost': 0,
                    'count': 0, 
                    'costs': [],
                    'min_cost': 0,
                    'max_cost': 0,
                    'median_cost': 0
                }
        
        # è½¬æ¢è¯¦ç»†ç»“æœä¸ºåˆ—è¡¨
        detailed_results = list(gateway_date_results.values())
        
        # ç¡®å®šæœ€ä½³ç®—æ³•ï¼ˆå¹³å‡æˆæœ¬æœ€ä½ï¼‰
        best_algorithm = None
        best_avg_cost = float('inf')
        
        for alg, stats in summary.items():
            if stats['count'] > 0 and stats['avg_cost'] < best_avg_cost:
                best_avg_cost = stats['avg_cost']
                best_algorithm = alg
        
        # è®¡ç®—ç®—æ³•é—´çš„æ€§èƒ½å·®å¼‚
        performance_difference = {}
        if summary['linear_programming']['count'] > 0:
            lp_avg = summary['linear_programming']['avg_cost']
            
            if summary['rule_based']['count'] > 0:
                rule_avg = summary['rule_based']['avg_cost']
                performance_difference['rule_vs_linear'] = {
                    'difference': rule_avg - lp_avg,
                    'percentage': ((rule_avg - lp_avg) / lp_avg) * 100 if lp_avg != 0 else 0
                }
            
            if summary['dynamic_programming']['count'] > 0:
                dp_avg = summary['dynamic_programming']['avg_cost']
                performance_difference['dp_vs_linear'] = {
                    'difference': dp_avg - lp_avg,
                    'percentage': ((dp_avg - lp_avg) / lp_avg) * 100 if lp_avg != 0 else 0
                }
        
        if summary['dynamic_programming']['count'] > 0 and summary['rule_based']['count'] > 0:
            dp_avg = summary['dynamic_programming']['avg_cost']
            rule_avg = summary['rule_based']['avg_cost']
            performance_difference['rule_vs_dp'] = {
                'difference': rule_avg - dp_avg,
                'percentage': ((rule_avg - dp_avg) / dp_avg) * 100 if dp_avg != 0 else 0
            }
        
        # æ·»åŠ hier_mpcç›¸å…³çš„æ€§èƒ½å¯¹æ¯”
        if summary['hier_mpc']['count'] > 0:
            hier_mpc_avg = summary['hier_mpc']['avg_cost']
            
            if summary['linear_programming']['count'] > 0:
                lp_avg = summary['linear_programming']['avg_cost']
                performance_difference['hier_mpc_vs_linear'] = {
                    'difference': hier_mpc_avg - lp_avg,
                    'percentage': ((hier_mpc_avg - lp_avg) / lp_avg) * 100 if lp_avg != 0 else 0
                }
            
            if summary['rule_based']['count'] > 0:
                rule_avg = summary['rule_based']['avg_cost']
                performance_difference['hier_mpc_vs_rule'] = {
                    'difference': hier_mpc_avg - rule_avg,
                    'percentage': ((hier_mpc_avg - rule_avg) / rule_avg) * 100 if rule_avg != 0 else 0
                }
            
            if summary['dynamic_programming']['count'] > 0:
                dp_avg = summary['dynamic_programming']['avg_cost']
                performance_difference['hier_mpc_vs_dp'] = {
                    'difference': hier_mpc_avg - dp_avg,
                    'percentage': ((hier_mpc_avg - dp_avg) / dp_avg) * 100 if dp_avg != 0 else 0
                }
        
        return {
            'summary': summary,
            'detailed_results': detailed_results,
            'best_algorithm': best_algorithm,
            'performance_difference': performance_difference
        }
        
    except Exception as e:
        print(f"ç®—æ³•æ€§èƒ½å¯¹æ¯”åˆ†æå¤±è´¥: {e}")
        return {}

def process_one_gateway_one_day(
    gateway_id, 
    day,
    rule_df,
    load_df,
    sun_df,
    tariff_df,
    battery_info_df):

    bat_info = extract_battery_info(battery_info_df, gateway_id)
    if bat_info is None:
        return None
    elif None in bat_info:
        return None
    else:
        _rated_cap, _soc_min, _curr_soc, _rated_power = bat_info
        _rated_cap, _soc_min, _curr_soc, _rated_power = _rated_cap*1000, _soc_min/100, _curr_soc/100, _rated_power*1000

    # ä¼˜åŒ–ï¼šé¢„å…ˆç­›é€‰è¯¥gateway_idå’Œæ—¥æœŸçš„æ‰€æœ‰æ•°æ®ï¼Œé¿å…é‡å¤æŸ¥æ‰¾
    rule_filtered = rule_df[(rule_df['gateway_id'] == gateway_id) & 
                           (rule_df['device_time'] == day)].copy()
    load_filtered = load_df[load_df['gateway_id'] == gateway_id].copy()
    sun_filtered = sun_df[sun_df['gateway_id'] == gateway_id].copy()
    tariff_filtered = tariff_df[tariff_df['gateway_id'] == gateway_id].copy()
    
    # ä¸ºdatetimeæŸ¥æ‰¾åˆ›å»ºç´¢å¼•å­—å…¸ä»¥æé«˜æŸ¥æ‰¾é€Ÿåº¦
    load_lookup = {row['datetime']: row for _, row in load_filtered.iterrows()}
    sun_lookup = {row['datetime']: row for _, row in sun_filtered.iterrows()}
    tariff_lookup = {row['device_time']: row for _, row in tariff_filtered.iterrows()}

    pv_pred = []
    pv = []
    load_pred = []
    load = []
    buy_prices = []
    sell_prices = []
    load_priority = []
    solar_priority = []
    grid_charge_max = []
    grid_discharge_max = []
    code = []

    for i in range(24):
        time = get_time_string(i)
        datetime_str = day + " " + time
        
        # ä¼˜åŒ–çš„è§„åˆ™æ•°æ®æå–
        rule_data = extract_rule_data_optimized(rule_filtered, datetime_str)
        if rule_data is None:
            print(f"Error: Unable to extract rule data for gateway_id {gateway_id} on {day} {time}")
            break
        _code, _load_priority, _solar_priority, _grid_charge_max, _grid_discharge_max = rule_data
        if None in [_code, _load_priority, _solar_priority, _grid_charge_max, _grid_discharge_max]:
            print(f"Error: Unable to extract rule data for gateway_id {gateway_id} on {day} {time}")
            break
            
        # ä¼˜åŒ–çš„è´Ÿè½½å’Œå…‰ä¼æ•°æ®æå–
        load_sun_data = extract_load_sun_data_optimized(
            load_lookup, sun_lookup, tariff_lookup, datetime_str
        )
        if load_sun_data is None:
            print(f"Error: Unable to extract load and sun data for gateway_id {gateway_id} on {day} {time}")
            break
        _load_pred, _load, _sun_pred, _sun, _buy_price, _sell_price = load_sun_data
        if None in [_load_pred, _load, _sun_pred, _sun, _buy_price, _sell_price]:
            print(f"Error: Unable to extract load and sun data for gateway_id {gateway_id} on {day} {time}")
            break
            
        pv_pred.append(_sun_pred * 1000)
        pv.append(_sun*1000)
        load_pred.append(_load_pred*1000)
        load.append(_load*1000)
        buy_prices.append(_buy_price)
        sell_prices.append(_sell_price)
        load_priority.append(_load_priority)
        solar_priority.append(_solar_priority)
        grid_charge_max.append(_grid_charge_max*1000)
        grid_discharge_max.append(_grid_discharge_max*1000)
        code.append(_code)
    
    if len(pv_pred) != 24:
        return None
    else:
        sample = {
                    "gateway_id": gateway_id,
                    "date": day,
                    "rated_cap": _rated_cap,
                    "soc_min": _soc_min,
                    "curr_soc": _curr_soc,
                    "rated_power": _rated_power,
                    "pv_pred": pv_pred,
                    "pv": pv,
                    "load_pred": load_pred,
                    "load": load,
                    "buy_prices": buy_prices,
                    "sell_prices": sell_prices,
                    "load_priority": load_priority,
                    "solar_priority": solar_priority,
                    "grid_charge_max": grid_charge_max,
                    "grid_discharge_max": grid_discharge_max,
                    "code": code
                }
        return sample

def select_test_samples(
    rule_df,
    load_df,
    sun_df,
    tariff_df,
    battery_info_df,
    year=2024,
    num_day=180,
    num_gatwayid=20,
    seed=123):

    np.random.seed(seed)

    day_candidates = []
    for i in range(12):
        month = i+1
        if month in [1,3,5,7,8,10,12]:
            for day in range(1, 32):
                day_candidates.append("{}-{:02d}-{:02d}".format(year, month, day))
        else:
            for day in range(1, 31):
                day_candidates.append("{}-{:02d}-{:02d}".format(year, month, day))

    day_candidates = np.random.permutation(day_candidates)
    day_candidates = day_candidates[:num_day]
    print("\n".join(day_candidates.tolist()))
    gateway_id_list = list(battery_info_df["gateway_id"])
    gateway_id_list = np.random.permutation(gateway_id_list)
    gateway_id_list = gateway_id_list[:num_gatwayid]
    print("\n".join(gateway_id_list.tolist()))
    
    samples = []
    futures = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:
        for gateway_id in gateway_id_list:
            for day in day_candidates:
                futures.append(
                    executor.submit(
                        process_one_gateway_one_day, 
                        gateway_id, 
                        day, 
                        rule_df,
                        load_df,
                        sun_df,
                        tariff_df,
                        battery_info_df)
                )
        for future in concurrent.futures.as_completed(futures):
            sample = future.result()
            if sample is not None:
                samples.append(sample)
            print(len(samples))
    return samples


def create_algorithm_comparison_charts(comparison_result: dict, output_dir: str = "algorithm_charts"):
    """
    åˆ›å»ºç®—æ³•å¯¹æ¯”å›¾è¡¨å¹¶ä¿å­˜
    
    Args:
        comparison_result: ç®—æ³•å¯¹æ¯”ç»“æœå­—å…¸
        output_dir: è¾“å‡ºç›®å½•
    """
    if not comparison_result:
        print("âŒ æ— æ³•ç”Ÿæˆå›¾è¡¨ï¼šæ•°æ®ä¸ºç©º")
        return
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(output_dir, exist_ok=True)
    
    summary = comparison_result.get('summary', {})
    
    # è®¾ç½®ä¸­æ–‡å­—ä½“å’Œå›¾è¡¨æ ·å¼
    #plt.rcParams['font.sans-serif'] = ['Heiti TC', 'DejaVu Sans']
    #plt.rcParams['axes.unicode_minus'] = False
    #sns.set_style("whitegrid")
    
    # ç®—æ³•åç§°æ˜ å°„
    alg_names = {
        'linear_programming': 'çº¿æ€§è§„åˆ’',
        'rule_based': 'è§„åˆ™æ–¹æ³•', 
        'dynamic_programming': 'åŠ¨æ€è§„åˆ’',
        'hier_mpc': 'åˆ†å±‚MPC'
    }
    
    # 1. å¹³å‡æˆæœ¬å¯¹æ¯”æŸ±çŠ¶å›¾
    create_average_cost_chart(summary, alg_names, output_dir)
    
    # 2. èƒœç‡å¯¹æ¯”å›¾
    create_win_rate_chart(comparison_result, alg_names, output_dir)
    
    # 3. æˆæœ¬åˆ†å¸ƒç®±çº¿å›¾
    create_cost_distribution_chart(comparison_result, alg_names, output_dir)
    
    # 4. ç®—æ³•æ€§èƒ½å·®å¼‚å¯¹æ¯”å›¾
    create_performance_difference_chart(comparison_result, output_dir)
    
    print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜åˆ° {output_dir}/ ç›®å½•")


def create_average_cost_chart(summary: dict, alg_names: dict, output_dir: str):
    """åˆ›å»ºå¹³å‡æˆæœ¬å¯¹æ¯”æŸ±çŠ¶å›¾"""
    algorithms = []
    avg_costs = []
    counts = []
    
    for alg, stats in summary.items():
        if stats['count'] > 0:
            algorithms.append(alg_names.get(alg, alg))
            avg_costs.append(stats['avg_cost'])
            counts.append(stats['count'])
    
    if not algorithms:
        return
    algorithms=["è§„åˆ™æ–¹æ³•", "MILP", "MPC", "MPC(20%)", "MPC(50%)", "MPC(100%)"]
    plt.figure(figsize=(10, 6))
    colors = ['#ff9999', '#66b3ff', '#99ff99', '#ffcc99']
    bars = plt.bar(algorithms, avg_costs, color=colors[:len(algorithms)])
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, (bar, cost, count) in enumerate(zip(bars, avg_costs, counts)):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + (0.01 if height >= 0 else -0.05),
                f'{cost:.3f}ç¾å…ƒ', ha='center', va='bottom' if height >= 0 else 'top')
    
    plt.title('ç®—æ³•å¹³å‡æˆæœ¬å¯¹æ¯”', fontsize=16, fontweight='bold')
    plt.xlabel('ç®—æ³•ç±»å‹', fontsize=12)
    plt.ylabel('å¹³å‡æˆæœ¬ (ç¾å…ƒ)', fontsize=12)
    plt.grid(True, alpha=0.3)
    
    # è®¾ç½®é¢œè‰²æ¡ä¾‹è¯´æ˜
    legend_labels = [f'{alg} (n={count})' for alg, count in zip(algorithms, counts)]
    plt.legend(bars, legend_labels, loc='upper right')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'average_cost_comparison.png'), dpi=300, bbox_inches='tight')
    plt.close()


def create_win_rate_chart(comparison_result: dict, alg_names: dict, output_dir: str):
    """åˆ›å»ºèƒœç‡å¯¹æ¯”å›¾"""
    detailed_results = comparison_result.get('detailed_results', [])
    
    if not detailed_results:
        return
    
    # ç»Ÿè®¡æ¯ä¸ªç®—æ³•çš„èƒœåˆ©æ¬¡æ•°
    algorithm_wins = {
        'linear_programming': 0,
        'rule_based': 0,
        'dynamic_programming': 0,
        'hier_mpc': 0
    }
    
    total_comparisons = 0
    
    # éå†æ¯ä¸ªgateway_idå’Œæ—¥æœŸçš„å¯¹æ¯”ç»“æœ
    for result in detailed_results:
        # è·å–è¯¥æ¡è®°å½•ä¸­æ‰€æœ‰ç®—æ³•çš„æˆæœ¬
        costs = {}
        for alg in algorithm_wins.keys():
            if alg in result and result[alg] is not None:
                costs[alg] = result[alg]
        
        # å¦‚æœè‡³å°‘æœ‰2ä¸ªç®—æ³•æœ‰æ•°æ®ï¼Œæ‰è¿›è¡Œæ¯”è¾ƒ
        if len(costs) >= 2:
            # æ‰¾åˆ°æˆæœ¬æœ€ä½çš„ç®—æ³•
            min_cost = min(costs.values())
            winners = [alg for alg, cost in costs.items() if cost == min_cost]
            
            # å¦‚æœæœ‰å¹¶åˆ—æœ€ä¼˜ï¼Œæ¯ä¸ªç®—æ³•åˆ†å¾—èƒœåˆ©åˆ†æ•°
            win_score = 1.0 / len(winners)
            for winner in winners:
                algorithm_wins[winner] += win_score
            
            total_comparisons += 1
    
    if total_comparisons == 0:
        return
    
    # è®¡ç®—èƒœç‡
    algorithms = []
    win_rates = []
    win_counts = []
    
    for alg, wins in algorithm_wins.items():
        if wins > 0:  # åªæ˜¾ç¤ºæœ‰èƒœåˆ©è®°å½•çš„ç®—æ³•
            algorithms.append(alg_names.get(alg, alg))
            win_rate = (wins / total_comparisons) * 100
            win_rates.append(win_rate)
            win_counts.append(wins)
    
    if not algorithms:
        return
    
    plt.figure(figsize=(12, 6))
    colors = ['#ff6b6b', '#4ecdc4', '#45b7d1', '#ffa726']
    bars = plt.bar(algorithms, win_rates, color=colors[:len(algorithms)])
    
    # æ·»åŠ èƒœç‡å’Œèƒœåˆ©æ¬¡æ•°æ ‡ç­¾
    for bar, rate, wins in zip(bars, win_rates, win_counts):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 1,
                f'{rate:.1f}%\n({wins:.0f}èƒœ)', ha='center', va='bottom')
    
    plt.title(f'ç®—æ³•èƒœç‡å¯¹æ¯” (æ€»å¯¹æ¯”: {total_comparisons}æ¬¡)', fontsize=16, fontweight='bold')
    plt.xlabel('ç®—æ³•ç±»å‹', fontsize=12)
    plt.ylabel('èƒœç‡ (%)', fontsize=12)
    plt.ylim(0, max(win_rates) * 1.2)
    plt.grid(True, alpha=0.3)
    
    # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬
    stats_text = f'ç»Ÿè®¡è¯´æ˜:\nâ€¢ æ€»å¯¹æ¯”æ¬¡æ•°: {total_comparisons}\nâ€¢ å¯¹æ¯”æ–¹å¼: åŒä¸€gateway_idåŒä¸€å¤©çš„ç®—æ³•æˆæœ¬æ¯”è¾ƒ\nâ€¢ èƒœåˆ©æ ‡å‡†: æˆæœ¬æœ€ä½çš„ç®—æ³•è·èƒœ'
    plt.text(0.02, 0.98, stats_text, transform=plt.gca().transAxes, 
            verticalalignment='top', bbox=dict(boxstyle='round', facecolor='lightblue', alpha=0.7))
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'win_rate_comparison.png'), dpi=300, bbox_inches='tight')
    plt.close()


def create_cost_distribution_chart(comparison_result: dict, alg_names: dict, output_dir: str):
    """åˆ›å»ºæˆæœ¬åˆ†å¸ƒç®±çº¿å›¾"""
    # è¿™é‡Œéœ€è¦ä»åŸå§‹æ•°æ®åˆ›å»ºåˆ†å¸ƒå›¾ï¼Œæš‚æ—¶ä½¿ç”¨æ±‡æ€»ç»Ÿè®¡åˆ›å»ºæ¨¡æ‹Ÿåˆ†å¸ƒ
    summary = comparison_result.get('summary', {})
    
    data_for_box = []
    labels = []
    
    for alg, stats in summary.items():
        if stats['count'] > 0:
            labels.append(alg_names.get(alg, alg))
            # ä½¿ç”¨ç»Ÿè®¡ä¿¡æ¯æ¨¡æ‹Ÿæ•°æ®åˆ†å¸ƒ
            avg = stats['avg_cost']
            min_val = stats['min_cost']
            max_val = stats['max_cost']
            median = stats['median_cost']
            
            # åˆ›å»ºæ¨¡æ‹Ÿæ•°æ®ç‚¹
            simulated_data = [
                min_val, 
                avg - (avg - min_val) * 0.5,
                median,
                avg,
                avg + (max_val - avg) * 0.5,
                max_val
            ] * (stats['count'] // 6 + 1)
            data_for_box.append(simulated_data[:stats['count']])
    
    if not data_for_box:
        return
    
    plt.figure(figsize=(12, 6))
    box_plot = plt.boxplot(data_for_box, labels=labels, patch_artist=True)
    
    # è®¾ç½®ç®±çº¿å›¾é¢œè‰²
    colors = ['#ffcccc', '#ccddff', '#ccffcc', '#ffe0cc']
    for patch, color in zip(box_plot['boxes'], colors[:len(data_for_box)]):
        patch.set_facecolor(color)
    
    plt.title('ç®—æ³•æˆæœ¬åˆ†å¸ƒå¯¹æ¯”', fontsize=16, fontweight='bold')
    plt.xlabel('ç®—æ³•ç±»å‹', fontsize=12)
    plt.ylabel('æˆæœ¬åˆ†å¸ƒ (å…ƒ)', fontsize=12)
    plt.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'cost_distribution.png'), dpi=300, bbox_inches='tight')
    plt.close()


def create_performance_difference_chart(comparison_result: dict, output_dir: str):
    """åˆ›å»ºç®—æ³•æ€§èƒ½å·®å¼‚å¯¹æ¯”å›¾"""
    performance_diff = comparison_result.get('performance_difference', {})
    
    if not performance_diff:
        return
    
    comparison_names = {
        'rule_vs_linear': 'è§„åˆ™æ–¹æ³• vs çº¿æ€§è§„åˆ’',
        'dp_vs_linear': 'åŠ¨æ€è§„åˆ’ vs çº¿æ€§è§„åˆ’',
        'rule_vs_dp': 'è§„åˆ™æ–¹æ³• vs åŠ¨æ€è§„åˆ’',
        'hier_mpc_vs_linear': 'åˆ†å±‚MPC vs çº¿æ€§è§„åˆ’',
        'hier_mpc_vs_rule': 'åˆ†å±‚MPC vs è§„åˆ™æ–¹æ³•',
        'hier_mpc_vs_dp': 'åˆ†å±‚MPC vs åŠ¨æ€è§„åˆ’'
    }
    
    comparisons = []
    differences = []
    percentages = []
    
    for comp, diff_data in performance_diff.items():
        if comp in comparison_names:
            comparisons.append(comparison_names[comp])
            differences.append(diff_data['difference'])
            percentages.append(diff_data['percentage'])
    
    if not comparisons:
        return
    
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
    
    # æˆæœ¬å·®å¼‚å›¾
    colors = ['red' if d > 0 else 'green' for d in differences]
    bars1 = ax1.bar(range(len(comparisons)), differences, color=colors, alpha=0.7)
    ax1.set_title('ç®—æ³•é—´æˆæœ¬å·®å¼‚ (å…ƒ)', fontsize=14, fontweight='bold')
    ax1.set_xlabel('å¯¹æ¯”ç»„åˆ', fontsize=12)
    ax1.set_ylabel('æˆæœ¬å·®å¼‚ (å…ƒ)', fontsize=12)
    ax1.set_xticks(range(len(comparisons)))
    ax1.set_xticklabels(comparisons, rotation=45, ha='right')
    ax1.grid(True, alpha=0.3)
    ax1.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, diff in zip(bars1, differences):
        height = bar.get_height()
        ax1.text(bar.get_x() + bar.get_width()/2., height + (0.001 if height >= 0 else -0.003),
                f'{diff:.3f}', ha='center', va='bottom' if height >= 0 else 'top')
    
    # ç™¾åˆ†æ¯”å·®å¼‚å›¾
    colors2 = ['red' if p > 0 else 'green' for p in percentages]
    bars2 = ax2.bar(range(len(comparisons)), percentages, color=colors2, alpha=0.7)
    ax2.set_title('ç®—æ³•é—´æˆæœ¬å·®å¼‚ (%)', fontsize=14, fontweight='bold')
    ax2.set_xlabel('å¯¹æ¯”ç»„åˆ', fontsize=12)
    ax2.set_ylabel('æˆæœ¬å·®å¼‚ (%)', fontsize=12)
    ax2.set_xticks(range(len(comparisons)))
    ax2.set_xticklabels(comparisons, rotation=45, ha='right')
    ax2.grid(True, alpha=0.3)
    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for bar, pct in zip(bars2, percentages):
        height = bar.get_height()
        ax2.text(bar.get_x() + bar.get_width()/2., height + (0.1 if height >= 0 else -0.3),
                f'{pct:.1f}%', ha='center', va='bottom' if height >= 0 else 'top')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, 'performance_difference.png'), dpi=300, bbox_inches='tight')
    plt.close()


def print_algorithm_comparison_report(comparison_result: dict):
    """
    æ‰“å°ç®—æ³•æ€§èƒ½å¯¹æ¯”æŠ¥å‘Š
    
    Args:
        comparison_result: compare_algorithm_performanceå‡½æ•°çš„è¿”å›ç»“æœ
    """
    if not comparison_result:
        print("âŒ æ— æ³•ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Šï¼šæ•°æ®ä¸ºç©º")
        return
    
    summary = comparison_result.get('summary', {})
    best_algorithm = comparison_result.get('best_algorithm')
    performance_diff = comparison_result.get('performance_difference', {})
    
    print("=" * 80)
    print("ğŸ” ç®—æ³•æ€§èƒ½å¯¹æ¯”åˆ†ææŠ¥å‘Š")
    print("=" * 80)
    
    print("\nğŸ“Š æ±‡æ€»ç»Ÿè®¡:")
    print("-" * 50)
    
    # ç®—æ³•åç§°æ˜ å°„
    alg_names = {
        'linear_programming': 'çº¿æ€§è§„åˆ’',
        'rule_based': 'è§„åˆ™æ–¹æ³•', 
        'dynamic_programming': 'åŠ¨æ€è§„åˆ’',
        'hier_mpc': 'åˆ†å±‚MPC'
    }
    
    for alg, stats in summary.items():
        if stats['count'] > 0:
            print(f"{alg_names.get(alg, alg)}:")
            print(f"  æ ·æœ¬æ•°é‡: {stats['count']}")
            print(f"  å¹³å‡æˆæœ¬: {stats['avg_cost']:.3f} å…ƒ")
            print(f"  æˆæœ¬èŒƒå›´: {stats['min_cost']:.3f} - {stats['max_cost']:.3f} å…ƒ")
            print(f"  ä¸­ä½æ•°: {stats['median_cost']:.3f} å…ƒ")
            
            # æˆæœ¬è§£é‡Š
            avg_cost = stats['avg_cost']
            if avg_cost > 0:
                print(f"  è´¢åŠ¡è¡¨ç°: å‡€æ”¯å‡º {abs(avg_cost):.3f} å…ƒ")
            elif avg_cost < 0:
                print(f"  è´¢åŠ¡è¡¨ç°: å‡€æ”¶ç›Š {abs(avg_cost):.3f} å…ƒ")
            else:
                print(f"  è´¢åŠ¡è¡¨ç°: æ”¶æ”¯å¹³è¡¡")
            print()
    
    # æœ€ä½³ç®—æ³•
    if best_algorithm:
        print(f"ğŸ† æœ€ä½³ç®—æ³•: {alg_names.get(best_algorithm, best_algorithm)}")
        print(f"   (å¹³å‡æˆæœ¬æœ€ä½: {summary[best_algorithm]['avg_cost']:.3f} å…ƒ)")
    
    print("\nğŸ“ˆ ç®—æ³•é—´æ€§èƒ½å·®å¼‚:")
    print("-" * 50)
    
    for comparison, diff_data in performance_diff.items():
        difference = diff_data['difference']
        percentage = diff_data['percentage']
        
        comparison_names = {
            'rule_vs_linear': 'è§„åˆ™æ–¹æ³• vs çº¿æ€§è§„åˆ’',
            'dp_vs_linear': 'åŠ¨æ€è§„åˆ’ vs çº¿æ€§è§„åˆ’',
            'rule_vs_dp': 'è§„åˆ™æ–¹æ³• vs åŠ¨æ€è§„åˆ’',
            'hier_mpc_vs_linear': 'åˆ†å±‚MPC vs çº¿æ€§è§„åˆ’',
            'hier_mpc_vs_rule': 'åˆ†å±‚MPC vs è§„åˆ™æ–¹æ³•',
            'hier_mpc_vs_dp': 'åˆ†å±‚MPC vs åŠ¨æ€è§„åˆ’'
        }
        
        print(f"{comparison_names.get(comparison, comparison)}:")
        
        if difference > 0:
            print(f"  æˆæœ¬å·®å¼‚: +{difference:.3f} å…ƒ (+{percentage:.1f}%)")
            print(f"  ç»“è®º: å‰è€…æˆæœ¬æ›´é«˜")
        elif difference < 0:
            print(f"  æˆæœ¬å·®å¼‚: {difference:.3f} å…ƒ ({percentage:.1f}%)")
            print(f"  ç»“è®º: å‰è€…æˆæœ¬æ›´ä½") 
        else:
            print(f"  æˆæœ¬å·®å¼‚: 0.000 å…ƒ (0.0%)")
            print(f"  ç»“è®º: æˆæœ¬ç›¸ç­‰")
        print()
    
    # è¯¦ç»†å»ºè®®
    print("ğŸ’¡ å»ºè®®:")
    print("-" * 50)
    
    if summary['linear_programming']['count'] > 0 and summary['rule_based']['count'] > 0:
        lp_avg = summary['linear_programming']['avg_cost']
        rule_avg = summary['rule_based']['avg_cost']
        
        if rule_avg < lp_avg:
            savings = lp_avg - rule_avg
            print(f"â€¢ è§„åˆ™æ–¹æ³•æ¯”çº¿æ€§è§„åˆ’å¹³å‡æ¯å¤©èŠ‚çœ {savings:.3f} å…ƒ")
        elif lp_avg < rule_avg:
            extra_cost = rule_avg - lp_avg
            print(f"â€¢ çº¿æ€§è§„åˆ’æ¯”è§„åˆ™æ–¹æ³•å¹³å‡æ¯å¤©èŠ‚çœ {extra_cost:.3f} å…ƒ")
    
    if summary['dynamic_programming']['count'] > 0:
        dp_avg = summary['dynamic_programming']['avg_cost']
        print(f"â€¢ åŠ¨æ€è§„åˆ’çš„å¹³å‡æ—¥æˆæœ¬ä¸º {dp_avg:.3f} å…ƒ")
        
        if best_algorithm == 'dynamic_programming':
            print("â€¢ åŠ¨æ€è§„åˆ’åœ¨å½“å‰æ•°æ®é›†ä¸Šè¡¨ç°æœ€ä½³ï¼Œå»ºè®®ä¼˜å…ˆä½¿ç”¨")
    
    print(f"\nğŸ“‹ æ•°æ®æ¦‚è§ˆ:")
    print(f"  æ€»åˆ†ææ–‡ä»¶å¤¹æ•°: {sum(stats['count'] for stats in summary.values())}")
    print(f"  æ¶µç›–ç®—æ³•ç±»å‹: {len([alg for alg, stats in summary.items() if stats['count'] > 0])}/4")
    
    # ç”Ÿæˆå¯¹æ¯”å›¾è¡¨
    print(f"\nğŸ“Š ç”Ÿæˆç®—æ³•å¯¹æ¯”å›¾è¡¨...")
    create_algorithm_comparison_charts(comparison_result)
   
def extract_rule_data_from_cache(rule_data_list: list, datetime: str) -> Optional[Tuple[str, list, list, int, int]]:
    """
    ä»ç¼“å­˜çš„è§„åˆ™æ•°æ®åˆ—è¡¨ä¸­æå–æŒ‡å®šdatetimeçš„é…ç½®ä¿¡æ¯
    
    Args:
        rule_data_list: è¯¥æ—¥æœŸçš„è§„åˆ™æ•°æ®åˆ—è¡¨
        datetime: æ—¶é—´å­—ç¬¦ä¸² (æ ¼å¼: 'YYYY-MM-DD HH:MM:SS')
    
    Returns:
        tuple: (dispatch_code, load_priority_list, solar_priority_list, grid_charge_max, grid_discharge_max)
    """
    try:
        from datetime import datetime as dt
        
        def priority_to_list(priority_val):
            """å°†priorityæ•°å­—è½¬æ¢ä¸º3å…ƒç´ åˆ—è¡¨"""
            # å¤„ç†NaNå€¼
            if pd.isna(priority_val):
                return [0, 0, 0]
            
            try:
                priority_int = int(float(priority_val))  # å…ˆè½¬æ¢ä¸ºfloatå†è½¬intï¼Œå¤„ç†å¯èƒ½çš„æµ®ç‚¹æ•°
                priority_str = str(priority_int)
                if len(priority_str) >= 3:
                    return [int(priority_str[0]), int(priority_str[1]), int(priority_str[2])]
                elif len(priority_str) == 2:
                    return [0, int(priority_str[0]), int(priority_str[1])]
                elif len(priority_str) == 1:
                    return [0, 0, int(priority_str[0])]
                else:
                    return [0, 0, 0]
            except (ValueError, TypeError):
                return [0, 0, 0]
        
        # è§£æè¾“å…¥çš„datetime
        input_dt = dt.strptime(datetime, '%Y-%m-%d %H:%M:%S')
        input_time_obj = input_dt.time()
        
        # æŸ¥æ‰¾æ—¶é—´èŒƒå›´åŒ¹é…çš„è§„åˆ™
        for row in rule_data_list:
            start_time = row['start_time']
            end_time = row['end_time']
            
            # å¤„ç†æ—¶é—´æ ¼å¼
            if len(start_time.split(':')) == 2:
                start_time = start_time + ':00'
            
            # å¤„ç†ç‰¹æ®Šæ—¶é—´æ ¼å¼ (24:00è¡¨ç¤ºå½“å¤©ç»“æŸ)
            if end_time == '24:00':
                end_time = '23:59:59'
            elif len(end_time.split(':')) == 2:
                end_time = end_time + ':00'
            
            # è½¬æ¢ä¸ºæ—¶é—´å¯¹è±¡è¿›è¡Œæ¯”è¾ƒ
            start_dt = dt.strptime(start_time, '%H:%M:%S').time()
            end_dt = dt.strptime(end_time, '%H:%M:%S').time()
            
            # æ£€æŸ¥æ—¶é—´æ˜¯å¦åœ¨èŒƒå›´å†…
            if start_dt <= input_time_obj <= end_dt:
                dispatch_code = str(row['dispatch_code'])
                load_priority_list = priority_to_list(row['load_priority'])
                solar_priority_list = priority_to_list(row['solar_priority'])
                
                # å¤„ç†grid_charge_maxå’Œgrid_discharge_maxçš„NaNå€¼
                try:
                    grid_charge_max = int(float(row['grid_charge_max'])) if not pd.isna(row['grid_charge_max']) else 0
                except (ValueError, TypeError):
                    grid_charge_max = 0
                    
                try:
                    grid_discharge_max = int(float(row['grid_discharge_max'])) if not pd.isna(row['grid_discharge_max']) else 0
                except (ValueError, TypeError):
                    grid_discharge_max = 0
                
                return (dispatch_code, load_priority_list, solar_priority_list, grid_charge_max, grid_discharge_max)
        
        return None
        
    except Exception as e:
        print(f"Error extracting rule data from cache: {e}")
        return None


def process_one_gateway_one_day_batch(gateway_ids: list, days: list, 
                                      rule_df, load_df, sun_df, tariff_df, battery_info_df):
    """
    æ‰¹é‡å¤„ç†å¤šä¸ªç½‘å…³å¤šå¤©çš„æ•°æ®ï¼Œè¿›ä¸€æ­¥ä¼˜åŒ–æ€§èƒ½
    
    Args:
        gateway_ids: ç½‘å…³IDåˆ—è¡¨
        days: æ—¥æœŸåˆ—è¡¨  
        rule_df, load_df, sun_df, tariff_df, battery_info_df: æ•°æ®è¡¨
    
    Returns:
        list: æ‰€æœ‰æœ‰æ•ˆæ ·æœ¬çš„åˆ—è¡¨
    """
    
    print(f"æ‰¹é‡å¤„ç† {len(gateway_ids)} ä¸ªç½‘å…³ï¼Œ{len(days)} å¤©æ•°æ®")
    
    # é¢„ç­›é€‰æ‰€æœ‰ç›¸å…³æ•°æ®ï¼Œå‡å°‘é‡å¤è¿‡æ»¤
    relevant_gateway_ids = set(gateway_ids)
    relevant_days = set(days)
    
    # æŒ‰ç½‘å…³IDé¢„ç­›é€‰æ•°æ®
    load_filtered = load_df[load_df['gateway_id'].isin(relevant_gateway_ids)].copy()
    sun_filtered = sun_df[sun_df['gateway_id'].isin(relevant_gateway_ids)].copy() 
    tariff_filtered = tariff_df[tariff_df['gateway_id'].isin(relevant_gateway_ids)].copy()
    rule_filtered = rule_df[(rule_df['gateway_id'].isin(relevant_gateway_ids)) & 
                           (rule_df['device_time'].isin(relevant_days))].copy()
    
    print(f"é¢„ç­›é€‰å®Œæˆ: Load({len(load_filtered)}), Sun({len(sun_filtered)}), Tariff({len(tariff_filtered)}), Rule({len(rule_filtered)})")
    
    # å¹¶è¡Œå¤„ç†
    samples = []
    futures = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:
        for gateway_id in gateway_ids:
            for day in days:
                futures.append(
                    executor.submit(
                        process_one_gateway_one_day,
                        gateway_id, day,
                        rule_filtered,  # ä½¿ç”¨é¢„ç­›é€‰çš„æ•°æ®
                        load_filtered,
                        sun_filtered, 
                        tariff_filtered,
                        battery_info_df
                    )
                )
        
        # æ”¶é›†ç»“æœ
        completed = 0
        total_tasks = len(futures)
        for future in concurrent.futures.as_completed(futures):
            sample = future.result()
            completed += 1
            if sample is not None:
                samples.append(sample)
            if completed % 50 == 0 or completed == total_tasks:  # æ˜¾ç¤ºè¿›åº¦
                print(f"æ‰¹é‡å¤„ç†è¿›åº¦: {completed}/{total_tasks} ({completed/total_tasks*100:.1f}%), æœ‰æ•ˆæ ·æœ¬: {len(samples)}")
    
    return samples


def create_gateway_data_cache(rule_df, load_df, sun_df, tariff_df, gateway_ids: list):
    """
    ä¸ºæŒ‡å®šçš„ç½‘å…³IDåˆ—è¡¨åˆ›å»ºæ•°æ®ç¼“å­˜ï¼Œè¿›ä¸€æ­¥æå‡æ‰¹é‡å¤„ç†æ€§èƒ½
    
    Args:
        rule_df, load_df, sun_df, tariff_df: åŸå§‹æ•°æ®è¡¨
        gateway_ids: éœ€è¦ç¼“å­˜çš„ç½‘å…³IDåˆ—è¡¨
    
    Returns:
        dict: ç¼“å­˜çš„æ•°æ®å­—å…¸ï¼ŒæŒ‰gateway_idç»„ç»‡
    """
    
    print(f"ä¸º {len(gateway_ids)} ä¸ªç½‘å…³åˆ›å»ºæ•°æ®ç¼“å­˜...")
    
    cache = {}
    
    for i, gateway_id in enumerate(gateway_ids):
        if i % 10 == 0:  # æ¯10ä¸ªç½‘å…³æ˜¾ç¤ºè¿›åº¦
            print(f"ç¼“å­˜è¿›åº¦: {i}/{len(gateway_ids)} ({i/len(gateway_ids)*100:.1f}%)")
            
        # ç­›é€‰è¯¥ç½‘å…³çš„æ‰€æœ‰æ•°æ®
        gateway_load = load_df[load_df['gateway_id'] == gateway_id].copy()
        gateway_sun = sun_df[sun_df['gateway_id'] == gateway_id].copy()
        gateway_tariff = tariff_df[tariff_df['gateway_id'] == gateway_id].copy()
        gateway_rule = rule_df[rule_df['gateway_id'] == gateway_id].copy()
        
        # åˆ›å»ºdatetimeæŸ¥æ‰¾å­—å…¸ï¼Œæ—¶é—´å¤æ‚åº¦O(1)
        load_lookup = {row['datetime']: row for _, row in gateway_load.iterrows()}
        sun_lookup = {row['datetime']: row for _, row in gateway_sun.iterrows()}
        tariff_lookup = {row['device_time']: row for _, row in gateway_tariff.iterrows()}
        
        # æŒ‰æ—¥æœŸç»„ç»‡è§„åˆ™æ•°æ®
        rule_by_date = {}
        for _, row in gateway_rule.iterrows():
            date = row['device_time']
            if date not in rule_by_date:
                rule_by_date[date] = []
            rule_by_date[date].append(row)
        
        cache[gateway_id] = {
            'load_lookup': load_lookup,
            'sun_lookup': sun_lookup, 
            'tariff_lookup': tariff_lookup,
            'rule_by_date': rule_by_date,
            'data_counts': {
                'load': len(gateway_load),
                'sun': len(gateway_sun),
                'tariff': len(gateway_tariff), 
                'rule': len(gateway_rule)
            }
        }
    
    print(f"æ•°æ®ç¼“å­˜åˆ›å»ºå®Œæˆï¼Œç¼“å­˜äº† {len(cache)} ä¸ªç½‘å…³çš„æ•°æ®")
    return cache


def process_one_gateway_one_day_cached(gateway_id: str, day: str, 
                                       gateway_cache: dict, battery_info_df):
    """
    ä½¿ç”¨ç¼“å­˜æ•°æ®å¤„ç†å•ä¸ªç½‘å…³å•å¤©æ•°æ®ï¼Œæœ€å¤§åŒ–æ€§èƒ½
    
    Args:
        gateway_id: ç½‘å…³ID
        day: æ—¥æœŸå­—ç¬¦ä¸²
        gateway_cache: è¯¥ç½‘å…³çš„ç¼“å­˜æ•°æ®
        battery_info_df: ç”µæ± ä¿¡æ¯æ•°æ®è¡¨
    
    Returns:
        dict: æ ·æœ¬æ•°æ®æˆ–None
    """
    
    # æå–ç”µæ± ä¿¡æ¯ï¼ˆåªéœ€æ‰§è¡Œä¸€æ¬¡ï¼‰
    bat_info = extract_battery_info(battery_info_df, gateway_id)
    if bat_info is None or None in bat_info:
        return None
    
    _rated_cap, _soc_min, _curr_soc, _rated_power = bat_info
    _rated_cap, _soc_min, _curr_soc, _rated_power = _rated_cap*1000, _soc_min/100, _curr_soc/100, _rated_power*1000
    
    # è·å–ç¼“å­˜çš„æŸ¥æ‰¾å­—å…¸ï¼ˆO(1)è®¿é—®ï¼‰
    load_lookup = gateway_cache['load_lookup']
    sun_lookup = gateway_cache['sun_lookup']
    tariff_lookup = gateway_cache['tariff_lookup']
    rule_by_date = gateway_cache['rule_by_date']
    
    # è·å–è¯¥æ—¥æœŸçš„è§„åˆ™æ•°æ®
    if day not in rule_by_date:
        return None
    rule_data_list = rule_by_date[day]
    
    # åˆå§‹åŒ–ç»“æœåˆ—è¡¨
    pv_pred, pv, load_pred, load = [], [], [], []
    buy_prices, sell_prices = [], []
    load_priority, solar_priority = [], []
    grid_charge_max, grid_discharge_max = [], []
    code = []
    
    for i in range(24):
        time = get_time_string(i)
        datetime_str = day + " " + time
        
        # ä»ç¼“å­˜ä¸­æå–è§„åˆ™æ•°æ®ï¼ˆé¿å…é‡å¤DataFrameè¿‡æ»¤ï¼‰
        rule_data = extract_rule_data_from_cache(rule_data_list, datetime_str)
        if rule_data is None:
            return None
        _code, _load_priority, _solar_priority, _grid_charge_max, _grid_discharge_max = rule_data
        
        # ä»ç¼“å­˜ä¸­æå–è´Ÿè½½å’Œå…‰ä¼æ•°æ®ï¼ˆO(1)å­—å…¸æŸ¥æ‰¾ï¼‰
        load_sun_data = extract_load_sun_data_optimized(load_lookup, sun_lookup, tariff_lookup, datetime_str)
        if load_sun_data is None:
            return None
        _load_pred, _load, _sun_pred, _sun, _buy_price, _sell_price = load_sun_data
        
        # æ·»åŠ åˆ°ç»“æœï¼ˆåˆ—è¡¨appendæ“ä½œï¼‰
        pv_pred.append(_sun_pred * 1000)
        pv.append(_sun * 1000)
        load_pred.append(_load_pred * 1000)
        load.append(_load * 1000)
        buy_prices.append(_buy_price)
        sell_prices.append(_sell_price)
        load_priority.append(_load_priority)
        solar_priority.append(_solar_priority)
        grid_charge_max.append(_grid_charge_max * 1000)
        grid_discharge_max.append(_grid_discharge_max * 1000)
        code.append(_code)
    
    if len(pv_pred) != 24:
        return None
    
    return {
        "gateway_id": gateway_id,
        "date": day,
        "rated_cap": _rated_cap,
        "soc_min": _soc_min,
        "curr_soc": _curr_soc,
        "rated_power": _rated_power,
        "pv_pred": pv_pred,
        "pv": pv,
        "load_pred": load_pred,
        "load": load,
        "buy_prices": buy_prices,
        "sell_prices": sell_prices,
        "load_priority": load_priority,
        "solar_priority": solar_priority,
        "grid_charge_max": grid_charge_max,
        "grid_discharge_max": grid_discharge_max,
        "code": code
    }


def benchmark_processing_methods(gateway_ids, days, rule_df, load_df, sun_df, tariff_df, battery_info_df, sample_size=10):
    """
    å¯¹æ¯”ä¸åŒå¤„ç†æ–¹æ³•çš„æ€§èƒ½
    
    Args:
        gateway_ids, days: ç½‘å…³IDå’Œæ—¥æœŸåˆ—è¡¨
        rule_df, load_df, sun_df, tariff_df, battery_info_df: æ•°æ®è¡¨
        sample_size: æµ‹è¯•æ ·æœ¬æ•°é‡
    """
    import time
    
    # é€‰æ‹©å°æ ·æœ¬è¿›è¡Œæ€§èƒ½æµ‹è¯•
    test_gateway_ids = gateway_ids[:sample_size//2] if len(gateway_ids) > sample_size//2 else gateway_ids
    test_days = days[:sample_size//len(test_gateway_ids)] if len(days) > sample_size//len(test_gateway_ids) else days
    
    print(f"æ€§èƒ½å¯¹æ¯”æµ‹è¯•: {len(test_gateway_ids)} ç½‘å…³ x {len(test_days)} å¤© = {len(test_gateway_ids) * len(test_days)} æ ·æœ¬")
    
    # æ–¹æ³•1: åŸå§‹æ–¹æ³•
    print("\næµ‹è¯•åŸå§‹æ–¹æ³•...")
    start_time = time.time()
    original_samples = []
    for gateway_id in test_gateway_ids:
        for day in test_days:
            sample = process_one_gateway_one_day(gateway_id, day, rule_df, load_df, sun_df, tariff_df, battery_info_df)
            if sample:
                original_samples.append(sample)
    original_time = time.time() - start_time
    
    # æ–¹æ³•2: ç¼“å­˜æ–¹æ³•
    print("\næµ‹è¯•ç¼“å­˜æ–¹æ³•...")
    start_time = time.time()
    cache = create_gateway_data_cache(rule_df, load_df, sun_df, tariff_df, test_gateway_ids)
    cached_samples = []
    for gateway_id in test_gateway_ids:
        for day in test_days:
            sample = process_one_gateway_one_day_cached(gateway_id, day, cache[gateway_id], battery_info_df)
            if sample:
                cached_samples.append(sample)
    cached_time = time.time() - start_time
    
    # è¾“å‡ºå¯¹æ¯”ç»“æœ
    print(f"\næ€§èƒ½å¯¹æ¯”ç»“æœ:")
    print(f"åŸå§‹æ–¹æ³•: {original_time:.2f}ç§’, æ ·æœ¬æ•°: {len(original_samples)}")
    print(f"ç¼“å­˜æ–¹æ³•: {cached_time:.2f}ç§’, æ ·æœ¬æ•°: {len(cached_samples)}")
    print(f"æ€§èƒ½æå‡: {original_time/cached_time:.1f}x")
    print(f"å¹³å‡æ¯æ ·æœ¬å¤„ç†æ—¶é—´: åŸå§‹{original_time/len(original_samples)*1000:.1f}ms, ç¼“å­˜{cached_time/len(cached_samples)*1000:.1f}ms")
    
    return {
        'original_time': original_time,
        'cached_time': cached_time,
        'speedup': original_time/cached_time,
        'original_samples': len(original_samples),
        'cached_samples': len(cached_samples)
    }

def select_test_samples_cache(
    rule_df,
    load_df,
    sun_df,
    tariff_df,
    battery_info_df,
    year=2024,
    num_day=180,
    num_gatwayid=50,
    seed=123):
    np.random.seed(seed)

    day_candidates = []
    for i in range(12):
        month = i+1
        if month in [1,3,5,7,8,10,12]:
            for day in range(1, 32):
                day_candidates.append("{}-{:02d}-{:02d}".format(year, month, day))
        else:
            for day in range(1, 31):
                day_candidates.append("{}-{:02d}-{:02d}".format(year, month, day))

    day_candidates = np.random.permutation(day_candidates)
    day_candidates = day_candidates[:num_day]
    print("\n".join(day_candidates.tolist()))
    gateway_id_list = list(battery_info_df["gateway_id"])
    gateway_id_list = np.random.permutation(gateway_id_list)
    gateway_id_list = gateway_id_list[:num_gatwayid]
    print("\n".join(gateway_id_list.tolist()))

    cache = create_gateway_data_cache(rule_df, load_df, sun_df, tariff_df, gateway_id_list)

    samples = []
    futures = []
    with concurrent.futures.ThreadPoolExecutor(max_workers=16) as executor:
        for gateway_id in gateway_id_list:
            for day in day_candidates:
                futures.append(
                    executor.submit(
                        process_one_gateway_one_day_cached, 
                        gateway_id, 
                        day, 
                        cache[gateway_id],
                        battery_info_df)
                )
        for future in concurrent.futures.as_completed(futures):
            sample = future.result()
            if sample is not None:
                samples.append(sample)
            print(len(samples))
    return samples


def plot_histogram_of_two_algo(algo1, algo2, res, bins=50):
    month = []
    error = []
    _dict = {}
    month_dist = {
        1: 0,
        2: 0,
        3: 0,
        4: 0,
        5: 0,
        6: 0,
        7: 0,
        8: 0,
        9: 0,
        10: 0,
        11: 0,
        12: 0,
    }
    for data in res["detailed_results"]:
        try:
            if data[algo1] != float("nan") and data[algo2] != float('nan'):
                error.append(data[algo1] - data[algo2])
                month.append(int(data["date"].split("-")[1]))
                _dict["gateway_id:{}-data:{}".format(data["gateway_id"], data["date"])] = data[algo1] - data[algo2]
                mm = int(data["date"].split("-")[1])
                if data[algo1] - data[algo2] < 0:
                    month_dist[mm] += 1
            else:
                continue
        except:
            continue

    sorted_items = sorted(_dict.items(), key=lambda item: item[1])
    sorted_dict = dict(sorted_items)

    with open("algorithm_charts/{}-{}_sorted_diff.json".format(algo1, algo2), "w") as f:
        json.dump(sorted_dict, f)

    x = [_x+1 for _x in range(12)]
    y = [month_dist[_x+1] for _x in range(12)]
    plt.bar(x, y) # bins control the number of bars
    plt.title('Low cost distribution')
    plt.xlabel('Month')
    plt.ylabel('Frequency')
    plt.savefig("algorithm_charts/{}-{}-lowcost-dist.png".format(algo1, algo2), dpi=300, bbox_inches='tight')
    plt.close()

    plt.hist(month, bins=12, edgecolor='black') # bins control the number of bars
    plt.title('Histogram of month')
    plt.xlabel('Month')
    plt.ylabel('Frequency')
    plt.savefig("algorithm_charts/month.png", dpi=300, bbox_inches='tight')
    plt.close()
    
    plt.hist(error, bins=bins, edgecolor='black') # bins control the number of bars
    plt.title('Histogram of {}-{}'.format(algo1, algo2))
    plt.xlabel('Value')
    plt.ylabel('Frequency')
    plt.savefig("algorithm_charts/{}-{}.png".format(algo1, algo2), dpi=300, bbox_inches='tight')
    plt.close()

    num_high_cost = 0
    num_low_cost05 = 0
    num_low_cost5 = 0
    for e in error:
        if e >= 0:
            num_high_cost += 1
        elif e >= -5:
            num_low_cost05 += 1
        else:
            num_low_cost5 += 1
    print([len(error), num_high_cost, num_low_cost05, num_low_cost5])
    patches, texts = plt.pie(
        [num_high_cost, num_low_cost05, num_low_cost5],
        labels=[str(num_high_cost), str(num_low_cost05), str(num_low_cost5)],
    )
    plt.legend(patches, [">=0", "-5-0", "<-5"], loc="best")
    plt.axis('equal')
    plt.title('Cost Differences Distribution')
    plt.savefig("algorithm_charts/{}-{}-distribution.png".format(algo1, algo2), dpi=300, bbox_inches='tight')
    plt.close()

def plot_error_statistics(samples):
    res = {"pv_error": [], "load_error": []}
    for sample in samples:
        pv_pred = sample["pv_pred"]
        pv_true = sample["pv"]
        load_pred = sample["load_pred"]
        load_true = sample["load"]
        pv_error_list = []
        load_error_list = []
        for i in range(24):
            if pv_true[i] == 0:
                pv_error=0
            else:
                pv_error = (pv_pred[i] - pv_true[i]) / pv_true[i]
        
            if load_true[i] == 0:
                load_error = 0
            else:
                load_error = (load_pred[i] - load_true[i]) / load_true[i]
            pv_error_list.append(pv_error)
            load_error_list.append(load_error)
        res["pv_error"].append(pv_error_list)
        res["load_error"].append(load_error_list)

    pv_error_mean = np.mean(np.array(res["pv_error"]), 0)
    pv_error_std = np.std(np.array(res["pv_error"]), 0)
    load_error_mean = np.mean(np.array(res["load_error"]), 0)
    load_error_std = np.std(np.array(res["load_error"]), 0)
    
    fig, (ax0, ax1) = plt.subplots(nrows=2, sharex=True)
    ax0.errorbar(range(len(pv_error_mean)), pv_error_mean, yerr=pv_error_std, fmt='-o')
    ax0.grid()
    ax0.set_title('å…‰ä¼é¢„æµ‹è¯¯å·®')

    ax1.errorbar(range(len(load_error_mean)), load_error_mean, yerr=load_error_std, fmt='-o')
    ax1.set_title('è´Ÿè½½é¢„æµ‹è¯¯å·®')
    ax1.grid()
    plt.savefig("algorithm_charts/error.png", dpi=300, bbox_inches='tight')
    plt.close()


if __name__ == "__main__":
    """
    with open("test_samples.json", "r", encoding='gbk') as f:
        data = json.load(f)
    plot_error_statistics(data)
    """
    """
    res = compare_algorithm_performance()
    with open("compare_algorithm_performance.json", "w") as f:
        json.dump(res, f)
    """
    with open("compare_algorithm_performance.json", "r") as f:
        res = json.load(f)
    plot_histogram_of_two_algo("rule_pred", "rule_based", res, 100)
    plot_histogram_of_two_algo("mpc_rule_gt", "rule_based", res, 100)
    plot_histogram_of_two_algo("mpc_rule_pred20", "rule_based", res, 100)
    plot_histogram_of_two_algo("mpc_rule_pred50", "rule_based", res, 100)
    plot_histogram_of_two_algo("mpc_rule_pred100", "rule_based", res, 100)
    print_algorithm_comparison_report(res)
    
    """
    rule_df = pd.read_csv('rule_dispath_data_md5.csv')
    load_df = pd.read_csv('kwh_load_md5.csv')
    sun_df = pd.read_csv('kwh_sun_md5.csv')
    tariff_df = pd.read_csv('tariff_info_md5.csv')
    battery_info_df = pd.read_csv('battery_info_md5.csv')
    
    samples = select_test_samples_cache(
        rule_df,
        load_df,
        sun_df,
        tariff_df,
        battery_info_df,
        year=2024,
        num_day=20,
        num_gatwayid=10,
        seed=123
    )
    with open("test_samples.json", "w") as f:
        json.dump(samples, f, indent=4)
    """